<?xml version="1.0" encoding="UTF-8"?>
<chapters>
<chapter> 
  <subject>managing node version nvm</subject>
   <content>
    <paragraph>
        <info>node version control (nvm)</info>
        <example>
------
Those are the steps for setting up node version control for mac os:


1. create .bashrc or .bash_profile in your home directory 

//update version 10.15.x the defualt bash is .zshrc so all commands apply to .zshrc

(unless you already have one created one of another)

  cd ~ 
  
//create 

  > .bashrc

2. use wget link to install nvm for the time of writing this it is 

    curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.37.2/install.sh | bash

3 bash script should be updated and then check if installation created directory:

    cd ~/.nvm 

4. reload the bash script where the nvm is saved 

   source ~/.bashrc 

4a. your .zshrc or .bashrc should have this written on 

export NVM_DIR="$HOME/.nvm"
[ -s "$NVM_DIR/nvm.sh" ] &#038;&#038; \. "$NVM_DIR/nvm.sh"  # This loads nvm
[ -s "$NVM_DIR/bash_completion" ] &#038;&#038; \. "$NVM_DIR/bash_completion"  # This loads nvm bash_completion

5. verify installation 

  command -v nvm

//or 

  nvm --version 


--------------------- installing node versions --------------------

1. install node version you required by 

    nvm install 12.13.0 
    nvm install 8.17.0  

or any version required 

2. set you default node by alias: 

    nvn alias default 12.13.0

3 set other alias

    nvm alias node8 8.17.0

    (or nvm alias name 8 major version if U have only one version istalled)

4. use default version by 

     nvm use default

4a. use other version or alias

     nvm use node8

-------------------------------------------------------------------------






        </example>
    </paragraph>
  </content>
  </chapter> 
  <chapter> 
    <subject>node package versions</subject>
    <content>

        <subtitle>install packages npm i</subtitle>
        <paragraph>
            <info>
      By defaualt any npm i/install package will install latest package with 'carret' minor version as loadash:'^1.3.4' alowing minor
      update to the version up below 2 as explained below:

      There are 3 type of npm semenatic vesrioning:

      major - upgrade from 1.0.0 to 2.00 (usually breaking changes)
      minor - upgrade from 1.0.0 to max 1.9.0 (no breaking changes, minor changes)
      patch - upgrade from 1.0.0 to max 1.0.9 (no breaking changes, bug fix)

      From mpm 5.x.x by npm install package-lock.json will be created that tracks all exact versions of the packages.


            </info>
            <example>
              /-- outcome in package.json----/

  npm i lodash -S/ --save produces loadash:'^1.3.4' allowed updated below 2.

  npm i lodash@1.4.5 -S/ --save produces loadash:'1.4.5' no updates version.

  npm i lodash -SE/ --save produces loadash:'1.7.4'(any latest same as npm i lodash@latest -SE/) not allowed updates.


  explained:
  //there is no information how to istall patch version of a package ~1.3.4 , so for now just need to be updated manually
  in package.json if needed.



            </example>
        </paragraph>
        <subtitle>npm update, npm </subtitle>
        <paragraph>
            <info>this will update all your package in a scope of the folder even if package-lock.json is present. 
/--/

npm update => updates project local packages

npm update packagename = updates one package 

npm update -g => updates globall installed packages

npm update packagename -g = updates one package installed globally 

there is some usufull npm commands that will tell you if your packages needs update to prevent errors
/--/

            </info>
            <example>
/----/

//list packages needed update locally / -g globally 
 -- npm outdated 



/-------- npm list ----------/

//view curent installed version locally / -g globally 
npm list --depth 0 

---IMPORATANT ---

this command also flags that which packages needs attentsion, update flaged as: UNMET PEER DEPENDENCY
U need to habe node_modules alredy present so after npm install. npm outdated it wont flag outdated packges
if they are not installed , so always run FIRST ::  npm list --depth 0 



//----------- npm update ----------/

this command will FIX all unmet depedencies regardless the package-lock.json versioning 
IMPORTANT any package needs updating it has to have minor or patch version enables in package.json
from node-sass:'1.3.4' it has to have node-sass:'^1.3.4' or node-sass:'`1.3.4'. It will not install 
update otherwise!

------------------------------------

//update all package / -g globally
-- npm update

//update single package / -g globally
-- npm update package

------ minor usage npm commands -------

//list all historical version about the package / -g globally
-- npm view enzyme versions

//clean unused dependencies (it wont fix unmet dependecies errors just will do repository clean up)
-- npm prune /or npm prun package

//package home page 
-- npm home package

//package repo page 
-- npm repo package

//package docs page 
-- npm docs package

//list curent bugs page 
 -- npm bugs package

/--/


</example>
        </paragraph>
        <subtitle>ENV variables accessed by process.env.VAR via dotenv package</subtitle>
        <paragraph>
            <info>global variables are useful for keeping secret data, tokens etc and the easiest to add new/manage them is 
            via dotenv npm package as below</info>
            <example>
                
1. ----- install dotenv npm package

npm install dotenv / yarn add dotenv

2. ---- create dot env config file in the root of your project --- .env ---
this file takes key pairs format ENV='value'

TOKEN='mysecret'
CUSTOM_USER='custom user'

3. -- request file in main node file as app.js when server starts

require('dotenv/config')

4. -----access variable in node process object

console.log(process.env.TOKEN)

            </example>
        </paragraph>
        <subtitle>finding nearest node executive</subtitle>
        <paragraph>
            <info>node executive for pacakges are kept in /bin directory and can be find by below commands</info>
            <example>
                
                /- find nearest node exectuble 
                //npm bin

                //once U have this you can run local package as gulp as:
                /Users/gilg/dev/myTuts/views/javascript_tuts/node_js_tuts/node_modules/.bin/gulp

                IMPORTANT package has to be in directory .bin/package and has to have executables as gulp does ;)


            </example>
        </paragraph>
    </content>
</chapter>
<chapter>
    <subject>Node Authentication</subject>
    <content>

        <subtitle>via sessionId and cookie</subtitle>
        <paragraph>
            <info>One of the way of Authenticating route is to set a session_Id at the 
            back-end and send it to front-end as cookie. Then any subsequent call to the server 
            will need that cookie to be send along for comparison to allow for execution of not.
     

            Cookie value === session_Id 

            IT MUST match in order to server to server the route

            </info>
            <example>
              /-- set session_Id in express---/

          In express the way to set up session id service is by middlware and the most popular 
          package is
                   npm i expess-session

  ------ once is intalled setup is set as any express middleware ------------

        app.use(session({
          secret: 'keyboard cat',
          resave: false,
          saveUninitialized: true
        }))

Above are the minimum basic flags that should be set there:

      secret: String that needs to match string in the cookie
      resave: 
      
      saveUninitialized: true|false 
      true => will not generate id if user is not authorized and 
      session object is modified and saved to memory store, file , database
      false => will generate id if user is not authorized 


            </example>
        </paragraph>
        <subtitle>how request know about cookie ? </subtitle>
        <paragraph>
            <info>this will update all your package in a scope of the folder even if package-lock.json is present. 
/--/

npm update => updates project local packages

npm update packagename = updates one package 

npm update -g => updates globall installed packages

npm update packagename -g = updates one package installed globally 

there is some usufull npm commands that will tell you if your packages needs update to prevent errors
/--/

            </info>
            <example>
/----/

//list packages needed update locally / -g globally 
 -- npm outdated 



/-------- npm list ----------/

//view curent installed version locally / -g globally 
npm list --depth 0 

---IMPORATANT ---

this command also flags that which packages needs attentsion, update flaged as: UNMET PEER DEPENDENCY
U need to habe node_modules alredy present so after npm install. npm outdated it wont flag outdated packges
if they are not installed , so always run FIRST ::  npm list --depth 0 



//----------- npm update ----------/

this command will FIX all unmet depedencies regardless the package-lock.json versioning 
IMPORTANT any package needs updating it has to have minor or patch version enables in package.json
from node-sass:'1.3.4' it has to have node-sass:'^1.3.4' or node-sass:'`1.3.4'. It will not install 
update otherwise!

------------------------------------

//update all package / -g globally
-- npm update

//update single package / -g globally
-- npm update package

------ minor usage npm commands -------

//list all historical version about the package / -g globally
-- npm view enzyme versions

//clean unused dependencies (it wont fix unmet dependecies errors just will do repository clean up)
-- npm prune /or npm prun package

//package home page 
-- npm home package

//package repo page 
-- npm repo package

//package docs page 
-- npm docs package

//list curent bugs page 
 -- npm bugs package

/--/


</example>
        </paragraph>
    </content>
</chapter>
<chapter>
    <subject>importing and exporting in Common.js</subject>
    <content>
      <subtitle>function, string exports/require </subtitle>
        <paragraph>
            <info>
            The CommonJS (CJS) format is used in Node.js and uses require and module.exports to define dependencies and modules. The npm ecosystem is built upon this format. There are 2 ways of exporting in Commonjs which is 
            deafult and named export. This one show how to export no-class js elements
            </info>
            <example>             

               /******** Two ways of exporting  ******/

              
              /1 ********** common.js default export function **************/

              function maxNumber(int1, int2) {
                  return Math.max(int1, int2);
                }

              module.exports = maxNumber;

              /1 ********** usage of default export *******/

              const anyName = require('./maxNumber')
              anyName(4,5)


              ..notice once default funcion export is required can take any name 
              but still it is the function we exported just under any name.
             /******************/

              /1a ********** common.js default export string **************/

               module.exports = 'anySring';
               const anyName = require('./module')
               //for a string
               console.log(anyName) //prints 'string'

                ..notice once default sting export is required can take any name 
              but still it is the string we exported just under any name.
             /******************/
                


              /2 ********** common.js function named export **************/

              function maxNumber(int1, int2) {
                  return Math.max(int1, int2);
                }

              module.exports.maxNumber = maxNumber;
              //or
              module.exports = { maxNumber };

               /2 ********** usage of default function export *******/

               const module = require('./generateRandomNumber')
               module.maxNumber Number(3, 10)


              /2a ********** common.js named export string **************/

               module.exports.myString = 'anySring';
               //or 
               module.exports = { myString: 'anySring' };

               const anyName = require('./module')
               //for a string
               console.log(anyName.myString) //prints 'string'



            </example>
        </paragraph>
        <subtitle>exports/require Class instance</subtitle>
        <paragraph>
            <info>
            The CommonJS (CJS) format is used in Node.js and uses require and module.exports to define dependencies and modules. The npm ecosystem is built upon this format. There are 2 ways of exporting in Commonjs which is 
            deafult and named export.
            </info>
            <example>             

               /******** Two ways of exporting  Module/Class******/

              
              /1 ********** common.js default export **************/

              class Operations {
                // Method
                maxNumber(int1, int2) {
                  return Math.max(int1, int2);
                }
              }

              module.exports = Operations;

              /1 ********** usage of default export *******/

              const Operations = require('./generateRandomNumber')
              const op = new Operations()
              op.maxNumber(3, 10)

             /******************/


              /2 ********** common.js named export **************/

               class Operations {
                // Method
                maxNumber(int1, int2) {
                  return Math.max(int1, int2);
                }
              }

              module.exports = Operations;


               /2 ********** usage of default export *******/

               const Operations = require('./generateRandomNumber').Operations
               const op = new Operations()
               op.max Number(3, 10)



            </example>
        </paragraph>
    </content>
</chapter>
<chapter>
    <subject>Default and Named export in Common.js and ES6</subject>
    <content>
        <paragraph>
            <info>
            if you enviroment accepst both standards Common.js you can use both 
            export/import format in conjunction.
            </info>
            <example>   
               /******** given maxNumber function ******/

                function maxNumber(int1, int2) {
                  return Math.max(int1, int2);
                }


               /******** deafult export both ES6 and common.js ******/

               //common.js
               module.exports = maxNumber;
               //ES6
               export default  maxNumber




               /******** named export both ES6 and common.js ******/

               //common.js
               module.exports.maxNumber = maxNumber;
               //or 
               module.exports = {maxNumber}

               //ES6
               export {maxNumber}
               //or 
               export function maxNumber(){}
               //or 
               export const maxNumber = () => {}


            </example>
        </paragraph>
    </content>
</chapter>
<chapter>
    <subject>node dubugging in Chrome</subject>
    <content>
        <subtitle>via chrome extension: simple file => node inspect</subtitle>
        <paragraph>
            <info>Dubbing node needs to be done in set up enviroment. Chrome build extension to make one and it could be 
              set up as: 
                    1. Run node (file/app) in debugg mode 

                        node inspsect file.js 
            </info>
            <example>
/***** Process of running dubugger for simple file ******/


1.  node inspsect file.js (notice is not node --inspect this one is resevered for file running server)

that produces a link as : 

    ws://127.0.0.1:9229/340e2dc2-bb4f-4744-bcfe-8d25788d3ef1 

copy this only : 

    127.0.0.1:9229/340e2dc2-bb4f-4744-bcfe-8d25788d3ef1 === localhost:9229/340e2dc2-bb4f-4744-bcfe-8d25788d3ef1

then U will get a message:
'Websockets request was expeceted'  ==> that means we need server running (point 2)

2.  it needs server to run thefore we need to provide one from node chrome extension 

    chrome://inspect 

will give you option to run server and pick file you want to debug on:
(it should be automatically detected)

 /******/

            </example>
        </paragraph>
         <subtitle>via chrome extension: simple file => node --inspect-brk</subtitle>
        <paragraph>
            <info>Dubbing node needs to be done in set up enviroment. Chrome build extension to make one and it could be 
              set up as: 
                    1. Run node (file/app) in debugg mode 

                        node --inspsect-brk file.js 

                    This allows you to run file and server in chrome extension at ones 
            </info>
            <example>
/***** Process of running dubugger for simple file ******/


1.  node inspsect file.js 

  node --inspsect-brk file.js

this command does both (doesnt produce link since open debug mode with server straigh away)


            </example>
          </paragraph>
            <subtitle>via chrome extension: RUN Sever => node --inspect </subtitle>
        <paragraph>
            <info>Dubbing node needs to be done in set up enviroment. Chrome build extension to make one and it could be 
              set up as: 

                  1. Run node (file/app) in debugg mode (either type or add to npm scripts)
 
                        node --inspsect-brk path/to/start/server.js  

                        node --inspsect path/to/start/server.js   

                      ----------- note ------------------
                        --inspsect and --inspsect-brk both => 

                        => Enable inspector agent
                        => Listen on default address and port (127.0.0.1:9229)

                        -----------
                        --inspsect-brk addtionally 

                        => Break before user code starts

                        -----------
            </info>
            <example>
              /***** Process of running dubugger for simple file ******/



//-------- example server.js -------------

1.  run your start server script (either by adding to npm scripts or type in console)

  node --inspsect path/to/start/server.js  

  //or 

  scripts:{
    start-debug:"node --inspsect path/to/start/server.js"
  }

2. this will prompt a message in console 

  'Debugger listening on ws://127.0.0.1:9....'

3. Open chrome inspect console url 

  chrome://inspect

//notification
4. U should have notification of 'REMOTE TARGET' being occupied by your running app 
5. click on link: 

      Open dedicated DevTools for Node

//Debugging
6. Open sources tab and CMD+P and look for the file to debug 
7. add your break point to the file and refresh the running app in the browser

------------------------------------------------

var express = require('express');
var app = express();

// process.env.PORT lets the port be set by Heroku
var port = 8080;

// set the home page route
app.get('/', function(req, res) {
  debugger;
  res.send('hi there printed')
});

app.listen(port, function() {
console.log('Our app is running on http://localhost:' + port);
});

//-------- example server.js -------------

2. Run sever in debug mode:

   node --inspsect-brk server.js 

3. set up websocket if previos command comes up with the link instead of opening debug chrome right away 

4. play with debugging rembering that u set up enviroment so the file wont work from beggining everytime if

  so if you are on : localhost:3000

  then the code after refreshing it will only come to here: 

  app.get('/', function(req, res) {
    debugger;
    res.send('hi there printed')
  });

  IT wont run entire file since it remmbers that this already run so just will run when is current state is 
  which is  app.get('/') for localhost:3000
  or any other route app.get('/test') for localhost:3000/test etc...

            </example>
        </paragraph>
        <subtitle>Chalk module helper for coloring console output</subtitle>
        <paragraph>
            <info>Chalk module allows to make diffrent font colors and background to easisly spot your logs 
              among other logs. so simply 

                  npm i -D chalk

              and start looking your logs in color ;) not black and white !

            </info>
            <example>
              

//-------- example server.js with chald debug color -------------

var express = require('express');
var app = express();
const chalk = require('chalk');

// process.env.PORT lets the port be set by Heroku
var port = 8080;

// set the home page route
app.get('/', function(req, res) {

  console.log(chalk.blue.bgRed.bold('Hello world!'));
  debugger
  res.send('hi there printed')
});

app.listen(port, function() {
console.log('Our app is running on http://localhost:' + port);
});

//-------- example server.js -------------



            </example>
        </paragraph>
    </content>
</chapter>
<chapter>
    <subject>VS code debug single file or server file (no config) </subject>
    <content>
        <paragraph>
            <info>VS code allow you to debug file without any configuration in node mode on mode mode(preview)</info>
            <example>

//--------- any file.js ------------------

1. open file file.js
2. click on debug icon and pick node.js
3. start debugging it should stop on break points or/and debbuggers keywords

 //---------------------------


  //--------- any server.js file ------------------
      //any file that can be previed since it outputs server response

1. open file server.js as 

-----------

    var express = require('express');
    var app = express();

    // process.env.PORT lets the port be set by Heroku
    var port = 8080;
    // set the home page route
    app.get('/', function (req, res) {
      debugger;
      res.send('hi there printed changed');
    });

    app.listen(port, function () {
      console.log('Our app is running on http://localhost::' + port);
    });

-----------

2. click on debug icon and pick ===>  node.js(preview)

3. start debugging it should stop on break points or/and debbuggers keywords

               //---------------------------

            </example>
        </paragraph>
         </content>
</chapter>
<chapter>
    <subject>VS code debug existing running server</subject>
    <content>
         <subtitle>(based on specific file</subtitle>
       <paragraph>
           <info>
              Sometimes you want attach debugger to existing running server and run specific file. Then you need below configuration

"configurations": [
    {
      "name": "Attach by server file",
      "request": "attach",
      "program": "${workspaceFolder}/server.js",
      "type": "node"
    }
  ]



           </info>
           <example>
             
1: set up configuration:

 "configurations": [
    {
      "name": "Attach by server file",
      "program": "${workspaceFolder}/server.js",
      "request": "attach",
      "type": "node"
    }
  ]

2: run your server application in terminal like for nodemon script

   npm run nodemon  

   (for script "nodemon":"nodemon serverFile.js" when you have local install)

3. then start your debugger sesion and pick the process id from the list for your running service 

4. go to your localhost:8080 and refresh the page it should stop at your break points or/and debbugerers 

           </example>
        </paragraph>
         <subtitle>(based on existing process)</subtitle>
       <paragraph>
           <info>
              Sometimes you want attach debugger to existing running server by process Id. Then you need below configuration

"configurations": [
    {
      "name": "Attach by Process ID",
      "processId": "${command:PickProcess}",
      "request": "attach",
      "type": "node"
    }
  ]



           </info>
           <example>
             
1: set up configuration:

 "configurations": [
    {
      "name": "Attach by Process ID",
      "processId": "${command:PickProcess}",
      "request": "attach",
      "type": "node"
    }
  ]

2: run your server application in terminal like for nodemon script

   npm run nodemon  

   (for script "nodemon":"nodemon serverFile.js" when you have local install)

3. then start your debugger sesion and pick the process id from the list for your running service 

4. go to your localhost:8080 and refresh the page it should stop at your break points or/and debbugerers 

           </example>
        </paragraph>
    </content>
</chapter>
<chapter>
    <subject>diffrence between exports.sth and module.exports = {} </subject>
    <content>
        <paragraph>
            <info>module.exports = {} usually exports an object,function , once exports.sth can export anything . 
              Rules:  
                1. U can not user module.exports = {} and exports in the same file
                2. module.exports = {} can be only one in the file. As defualt export in ES6 modules.
                3. exports can be used multiple times in the file. As { named exports } in ES6 modules.

                in short !!
                As module.exports and exports both point to the same object, it doesn’t normally matter which you use. 
                For example:

                  exports.foo = 'foo';
                  module.exports.bar = 'bar';

                //however for individual export U should use 
                exports.foo = 'foo';

                because it is possible to override module.exports object by below somewhere in the files

                module.exports = ()=>{ //some function }


            </info>
            <example>
/ --- export same object both ways ----/

  exports.text1 = 'text1';
  exports.text2 = 'text2';
  exports.text3 = 'text3';

/ --- request exports ---/

  var texts = require(./texts)
  console.log(texts.text1)
  console.log(texts.text2)
  console.log(texts.text3)

/ --- same with module.exports -----/

module.exports = {
  text1: 'text1',
  text2: 'text2',
  text3: 'text3',
}

/ --- request exports same way---/

  var texts = require(./texts)
  console.log(texts.text1)
  console.log(texts.text2)
  console.log(texts.text3)


/----  module.export exporting a function --- /

    module.exports = function(param){}

/ --- request exports and invoke---/

    require(./function)(param)

/ --- /

/----  module.export exporting a named function --- /

    function startJob(param){
      //it doesnt need to return as any function;
      return 'job started,'+param
    }

    module.exports.startJob = startJob
    //or 
    expors.startJob = startJob //preferable way since it doesnt intefere with global module.exports

/ --- request exports and invoke named function---/

    cosnt resultOfNamedFunction = require(./namedFunction).startJob('now');

    console.log(resultOfNamedFunction) //logs job started,now 

/ --- /

            </example>
        </paragraph>
    </content>
</chapter>
<chapter>
    <subject>simple express node server</subject>
    <content>
        <paragraph>
            <info>this is simple start up setup for node.js server with express it works on heroku as  well as localhost,
              it needs script in package.json: start:node file.js (file your sever below) it also supports ejs engine templating</info>
            <example>
--------- server.js ----------------

var express = require('express');
var app = express();
const bodyParser = require('body-parser');
const cors = require('cors')

// process.env.PORT lets the port be set by Heroku
  var port = process.env.PORT || 8080;

// set the view engine to ejs
  app.set('view engine', 'ejs');

// make express look in the public directory for assets (css/js/img)
  app.use(express.static(__dirname + '/public'));

app.use(cors())
app.use(bodyParser.json())
app.use(bodyParser.urlencoded({ extended: true }))

// set the home page route
app.get('/', function(req, res) {
  //U need to specify header the bare minimum
  res.header('Content-Type', 'text/html; charset=utf-8')
  res.render('index');
  //res.end('hi');
});

app.get('/json', (req, res) => {
  res.header('Content-Type', 'application/json; charset=utf-8')
  res.json({json:'it is json response object set'})
})

app.listen(port, function() {
console.log('Our app is running on http://localhost:' + port);
});

--------------------------------------------

            </example>
        </paragraph>
    </content>
</chapter>
<chapter>
    <subject>Express Middleware</subject>
     <content>
          <subtitle>what is express Middleware ?</subtitle>
       <paragraph>
            <info>Express is only resposible for routing which works on top of native node moduel http. For anything else is using middleware. And middle is short 
        is just a function(req,res,next) that execute and goes to the next() middlware function until we return res.next() or any other response.</info>
   <example>
        
/ ------- example middleware --------- /

app.use(function(res,req,next)=>{
//do your staff and return next() when U are done!
next();
//next will go to the next middleware function
})

/--- those are the most common middleware for exprsss ---/

app.use(cors())
app.use(bodyParser.json())
app.use(bodyParser.urlencoded({ extended: true }))

explanation:
cors is used for non-block sameorigin http calls
bodyparser alows you to get content of http request by req.body

/------ IMPORATANT even routes are constructed as middleware function ----/

app.get('/legos'),(req,res,next)=>{
//posible response 
rest.send()
res.header('Content-Type', 'application/json; charset=utf-8')
res.render('index');

/-----   but you could also call next() if there is no res.something() already 
/-----   route is the last on the list to visit that is why it needs to responded at that point not next()

}) 


    </example>
        </paragraph>
        <subtitle>types of express Middleware</subtitle>
        <paragraph>
            <info>
              There are several types of express middleware: U can devide them into internal and third-party middleware. The order you execute your middleware
              matters as explained below:
            </info>
            <example>
/ -------- /
application middleware/build-in middleware
/------/

those need to be executed first cause they are resposible for setting our static files
app.use(express.static('views'))

/ -------- /
third-party middleware
/------/

those depends what they do they should be executed before certain action being detected as for bodyParser before receiving routes
app.use(bodyParser.json())
app.use(bodyParser.urlencoded({ extended: true }))

/ ------ /
routes 
/---- / 

U might be suprise why routes are in a middlware section?, well they are part of them when we excute route We want to respond to the browser 
as res.render(index) but we can also handle error by next(error) to be send to our error middleware 

/ ------ /
error middleware (it always needs 4 params to detect from other middleware )
/---- / 

/lets assume we have below route that triggers error

app.get('/legos'),(req,res,next)=>{
  next(new Error('no way!'))
})
  app.use(function(err,res,req,next)=>{
  //handle error
  console.log(error)
  //do your staff and return next() when U are done!
  next();
})

/------/

            </example>
        </paragraph>
        <subtitle>custom middleware</subtitle>
        <paragraph>
            <info>the beauty of middleware is the fact that is just a function! so we can easily make custom ones to serve our purpose in a middlware chain.</info>
            <example>
/ ---- /
  custom middleware request it is with a dot adnotation so node recognize it as custom note a module from node_modules;
/ ----/

car customMiddlware = require('./custom')

/---- quite often our custom middleware is wrapped in higher order functio to pass some params ---/

const custom = (param)=>{
  return fuction(req,res,next){
  //do something 
  next()
  //move on to the next one...
  }
}

/---- execute custom middleware ----/

app.get('/legos', custom(param), function(req,res,)=>{
  res.render('I am cool now!')
})

explanation:
the custom midllware could be execute on route level, so the application gets to route and then executes the stack of middlware
on this level it could take fuctions or array of functions

app.get('/legos', custom(param),custom1(param), function(req,res,)=>{})

stack = [custom(param),custom1(param)];
app.get('/legos', stack, function(req,res,)=>{})


/ ---- /

            </example>
        </paragraph>
        <subtitle>Delegating work to the Middleware (multiuse abstraction)</subtitle>
        <paragraph>
            <info>Express comes with some helper middleware as app.param that alows you to do some logic outsite the route and then give you the result back in route</info>
            <example>
/--- let say U got route as one below ----/

/----
now every time we hit any route with id as 'legos/:i d' or 'lions/lion/:id' 
express can delegate what we can do with id in a seperate middlware 
 ----\

app.param('id', function(req,res,next){
  //do something with id
  next()
  //move on to next
})

/--- this route has to be after app.param --/
app.use('legos/:id',function(req,res){})

/--/
            </example>
        </paragraph>
    </content>
</chapter>
<chapter>
    <subject>express 4 routing and sub-routing</subject>
    <content>
        <subtitle>register routers</subtitle>
        <paragraph>
            <info>
              express 4.> allows you to register more that one router which a milestone from express 3. that hold everthing on app.router() level.
            </info>
            <example>
/ ---- regiser routets  ----/

var toDoListRouter = express.Router();
var guesscheckoutRouter = express.Router();

//now regiester them with the main app express;
app.use('/toDoListRouter',loginRouter)
app.use('/guesscheckout',guesscheckoutRouter)

explanation:
app.use('/guesscheckout',guesscheckoutRouter) middleware allows to delegate the work of handling any /guesscheckout/...
routes to the guesscheckoutRouter middleware

/-----/

            </example>
        </paragraph>
        <subtitle>sub-routing</subtitle>
        <paragraph>
            <info>sub-routing allow you to create addtional routes that derived from master route as app.get(/masterPath/)</info>
            <example>

/---- register our route with main app and delegate any /guesscheckout/additionalpath to loginRouter path ---/

app.use('/guesscheckout',guesscheckout)


/ ---- sub-routes to /guesscheckout path -----/

guesscheckout.get('/',function(req,res){
//this routes corresponds to /guesscheckout/ === /guesscheckout
res.render('..ok I will do it')}
)
guesscheckout.get('/:id',function(req,res){
 //this routes corresponds to /guesscheckout/:id 
res.render('..yeah I am a guest !')
})

info:
sub-routing are great for organizing, abstracting away your routes and put them in seperate file and simple export to require them in main server file:
module.exports = guesscheckout

 /----/

            </example>
        </paragraph>
        <subtitle>combining same route in object with app.route('/..')</subtitle>
        <paragraph>
            <info>lets say We have app.get('/lions') and then we have app.post('/lions'), we can put them in one place...</info>
            <example>
/ ------ request on the same route as: -----/

app.get('/lions',(req,res)=>{})
app.post('/lions'(req,res)=>{})

/ --- use app.route() to put them together --/

app.route('/lions')
.get('/lions',(req,res)=>{})
.post('/lions'(req,res)=>{})

/-----/

            </example>
        </paragraph>
    </content>
</chapter>
<chapter>
    <subject>express routes variables</subject>
    <content>
        <subtitle>within single route (read cookie and variables)</subtitle>
        <paragraph>
            <info>
            // available in single route with single response

            app.locals.title = 'My App'

            </info>
            <example>
/ ---- regiser routets  ----/

app.use('/greg', (req, res) => {
  res.cookie('cookie', 'monster')
  res.append('Set-Cookie', 'foo=bar; Path=/; HttpOnly')

  // The variables set on res.locals are available within a single request-response cycle, and will not be shared between requests.
  res.locals.custom = 'monster'
  // to make sharable attach to app.locals this is available as long as the app is running (if it reset is gone)
  app.locals.title = 'My App'

  res.status(200).send('initial')
})

app.use('/greg1', (req, res) => {
  // this reads cookie from browser
  const { cookies } = req
  const {
    locals: { title },
  } = app

  // all cookie set in the browser
  const { headers } = req

  res.status(200).send(JSON.stringify({ req: { cookies, headers }, app: { locals: { title } } }))
})

/-----/

            </example>
        </paragraph>
        <subtitle>single route with multiple response in array</subtitle>
        <paragraph>
            <info>when you have a single request with multiple responses then you have access to below variables
            
            // both accessible with single route with multiple responses

            res.locals.custom = 'monster'

            app.locals.title = 'My App'
            
            </info>
            <example>

/-------/

const req1 = (req, res, next) => {
  res.cookie('cookie', 'monster')
  res.append('Set-Cookie', 'foo=bar; Path=/; HttpOnly')

  // The variables set on res.locals are available within a single request-response cycle, and will not be shared between requests.
  res.locals.custom = 'monster'
  // to make sharable attach to app.locals this is available as long as the app is running (if it reset is gone)
  app.locals.title = 'My App'

  next()
}

const req2 = (req, res) => {
  // this reads cookie from browser
  const { cookies, headers } = req
  const {
    locals: { title },
  } = app

  const {
    locals: { custom },
  } = res

//this gives all? possible variables and cookies within single request and multiple responses

  res.status(200).send(
    JSON.stringify({
      app: { locals: { title } },
      res: { locals: { custom } },
      req: { cookies, headers },
    }),
  )
}

// single route multiple requests
app.use('/multipleResponses', [req1, req2])

 /----/

            </example>
        </paragraph>
    </content>
</chapter>
<chapter>
    <subject>MongoDB and mongoose</subject>
    <content>
        <subtitle>Define mongoDB connection and mongoose Schema</subtitle>
        <paragraph>
            <info>MongoDB is noSQL database , that is just a giant object that would exept any data without any validation. It needs 
              3th party products to make sure the data is set according the data models schema and is valid.</info>
            <example> 

/----- example mongoDb connection in node.js ---/

/ -----   /
var mongoose = require('mongoose');
var url = "mongodb://localhost:27017/mydb";
mongoose.connect('mongodb://localhost:27017/myapp', {useNewUrlParser: true});
/ -----   /
explanation:
mongodb://localhost:27017/myapp => where myApp is name of DB that is running on localhost PORT:27017
practically, If U plan to publish your app is better to set up your DB on host domain as myLAB for heroku

/ -----   /

            </example>
        </paragraph>
        <subtitle>Mongoose data types</subtitle>
        <paragraph>
            <info>Moongoose allows U to make schema therfore comes with some extra data types to make that happen.</info>
            <example>
/ ----------- /
  Sample data type are:
  String,
  Number,
  Boolean,
  Object,
  Array,
  OBjectId, (this is reference to other model)
Date,
/ ------ /

            </example>
        </paragraph>
        <subtitle>moongoose collection schema</subtitle>
        <paragraph>
            <info>mongoose allows U to crate schema for every collection you make in mongoDB making sure the data pass in is correct</info>
            <example>
              
/ ---   example mongoose schema ------/


var PostSchema = {
  title:{
    type:String,
    required:true,
    unique:true
  }
  text:{
    type:String,
    required:true
    }
  author:{
    type:Shema.Types.ObjectId
    ref:'user'
  }
  categories:[
    {
    type:Shema.Types.ObjectId
    ref:'category'
  }]
}

/---- the possible post could be: ----/
"posts":{
  "title": "Life of PI"
  "text": "Aparently is a great book and movie!"
  author: "ObjectId(436353453535353e423d)"
  categories:[
      "ObjectId(4r554353453535353e423d)",
      "ObjectId(43336353453535353e423d)"
      "ObjectId(55555353453535353e423d)"
  ]
}

explanation:
Post model has PostSchema that has fields: title, text, author, categories.
Notice that author and categories are diffrent: 
author is referenced in user Model with its ID.
categories are in array referenced in category Model by its IDs. so we dont bring categories name here if we want to access
them We would use their ids and fields set in Category Model. Therefore is so important to use GUI interface for choosing
reference type data to not make it mistake. Dont update them in code unless you know every category unique ID reference.


            </example>
        </paragraph>
        <subtitle>mongoose populate ID</subtitle>
        <paragraph>
            <info>It is possible to save the record without ObjectID in one of the fields and populate that field later in another post Query</info>
            <example>

/ --- / 
check if the field is populated ?

post.populated('author'); // truthy 

/ -- /

What about creating a post ?

/---- the possible post could be: ----/
  "posts":{
    "title": "Life of PI"
    "text": "Aparently is a great book and movie!"
    //author: NOT ADDED
    categories:[
        "ObjectId(4r554353453535353e423d)",
        "ObjectId(43336353453535353e423d)"
        "ObjectId(55555353453535353e423d)"
    ]
  }

explanation:
just because athour is not required and not unique field we can save our post without it. But that means we just created a post
who doesnt have an author. There are at least 2 wasy to fix that. 

1. use populate method as

  Post.
    findOne({ title: 'Casino Royale' })
    .populate('author')
    .exec(function (err, story) {
      if (err) return handleError(err);
      console.log('The author is %s', story.author.name);
      // prints "The author is Ian Fleming"
    });
This will look for Post title and populate with the ID of the only Author in collection. ONLY one is fine but what if there is more authors?
well then will go crazy. The moongoose documentation says this: 'If you have an array of authors in your storySchema, populate() will give you an empty array instead.' so unless U have only one author then will work otherwise dont use populate!

2. Another way of filling the author fiels is to grab current author ID and pass it in POST Query as merge object {author:ObjectID(83t34t),...rest} that way
we fill it right when post in created with the author that is logged in.


            </example>
        </paragraph>
    </content>
</chapter>

</chapters>